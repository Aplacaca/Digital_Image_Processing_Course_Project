# coding:utf-8
import torch
from torch import Tensor, nn
from torch.nn import init
from torch.nn import functional as F

from utils.prior_box import PriorBox
from detector import Detector


def vgg16(batch_norm=False) -> nn.ModuleList:
    """ åˆ›å»º vgg16 æ¨¡å‹

    Parameters
    ----------
    batch_norm: bool
        æ˜¯å¦åœ¨å·ç§¯å±‚åé¢æ·»åŠ æ‰¹å½’ä¸€åŒ–å±‚
    """
    layers = []
    in_channels = 3
    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256,
           256, 'C', 512, 512, 512, 'M', 512, 512, 512]

    for v in cfg:
        if v == 'M':
            layers.append(nn.MaxPool2d(2, 2))
        elif v == 'C':
            layers.append(nn.MaxPool2d(2, 2, ceil_mode=True))
        else:
            conv = nn.Conv2d(in_channels, v, 3, padding=1)

            # å¦‚æœéœ€è¦æ‰¹å½’ä¸€åŒ–çš„æ“ä½œå°±æ·»åŠ ä¸€ä¸ªæ‰¹å½’ä¸€åŒ–å±‚
            if batch_norm:
                layers.extend([conv, nn.BatchNorm2d(v), nn.ReLU(True)])
            else:
                layers.extend([conv, nn.ReLU(True)])

            in_channels = v

    # å°†åŸå§‹çš„ fc6ã€fc7 å…¨è¿æ¥å±‚æ›¿æ¢ä¸ºå·ç§¯å±‚
    layers.extend([
        nn.MaxPool2d(3, 1, 1),
        nn.Conv2d(512, 1024, 3, padding=6, dilation=6),  # conv6 ä½¿ç”¨ç©ºæ´å·ç§¯å¢åŠ æ„Ÿå—é‡
        nn.ReLU(True),
        nn.Conv2d(1024, 1024, 1),                        # conv7 ä½¿ç”¨å…¨å·ç§¯ç­‰æ•ˆå…¨è¿æ¥
        nn.ReLU(True)
    ])

    layers = nn.ModuleList(layers)

    return layers


class L2Norm(nn.Module):
    """ L2 æ ‡å‡†åŒ– """

    def __init__(self, n_channels: int, scale=20):
        """
        Parameters
        ----------
        n_channels: int
            é€šé“æ•°

        scale: float
            l2æ ‡å‡†åŒ–çš„ç¼©æ”¾æ¯”
        """
        super().__init__()
        self.gamma = scale
        self.eps = 1e-10
        self.n_channels = n_channels
        self.weight = nn.Parameter(Tensor(self.n_channels))
        self.reset_parameters()

    def reset_parameters(self):
        init.constant_(self.weight, self.gamma)

    def forward(self, x: Tensor):
        norm = (x.pow(2).sum(dim=1, keepdim=True)+self.eps).sqrt()
        x = torch.div(x, norm)
        # å°† weight çš„ç»´åº¦å˜ä¸º [1, n_channels, 1, 1]
        y = x*self.weight[None, ..., None, None]
        return y


class SSD(nn.Module):
    """ SSD ç¥ç»ç½‘ç»œæ¨¡å‹ """

    def __init__(self, n_classes: int, variance=(0.1, 0.2), top_k=10, conf_thresh=0.01,
                 nms_thresh=0.45, image_size=300, **config):
        """
        Parameters
        ----------
        n_classes: int
            è¦é¢„æµ‹çš„ç§ç±»æ•°ï¼ŒåŒ…æ‹¬èƒŒæ™¯

        variance: Tuple[float, float]
            å…ˆéªŒæ¡†çš„æ–¹å·®

        top_k: int
            æ¯ä¸ªç±»çš„è¾¹ç•Œæ¡†ä¸Šé™

        conf_thresh: float
            ç½®ä¿¡åº¦é˜ˆå€¼

        nms_thresh: float
            nms ä¸­ IOU é˜ˆå€¼

        image_size: int
            å›¾åƒå°ºå¯¸

        **config:
            å…³äºå…ˆéªŒæ¡†ç”Ÿæˆçš„é…ç½®
        """
        super().__init__()

        if len(variance) != 2:
            raise ValueError("variance åªèƒ½æœ‰ 2 å…ƒç´ ")

        self.n_classes = n_classes
        self.image_size = image_size
        self.priorbox_generator = PriorBox(image_size, **config)
        self.prior = Tensor(self.priorbox_generator())
        self.detector = Detector(
            n_classes, variance, top_k, conf_thresh, nms_thresh)

        self.vgg = vgg16()
        self.l2norm = L2Norm(512, 20)
        self.extras = nn.ModuleList([
            nn.Conv2d(1024, 256, 1),                        # conv8_2 å…¨å·ç§¯
            nn.Conv2d(256, 512, 3, stride=2, padding=1),
            nn.Conv2d(512, 128, 1),                         # conv9_2 å…¨å·ç§¯
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.Conv2d(256, 128, 1),                         # conv10_2 å…¨å·ç§¯
            nn.Conv2d(128, 256, 3),
            nn.Conv2d(256, 128, 1),                         # conv11_2 å…¨å·ç§¯
            nn.Conv2d(128, 256, 3),
        ])
        # multi-box layersï¼Œç”¨æ¥å›å½’å’Œåˆ†ç±»
        self.confs = nn.ModuleList([
            nn.Conv2d(512, n_classes*4, 3, padding=1),
            nn.Conv2d(1024, n_classes*6, 3, padding=1),
            nn.Conv2d(512, n_classes*6, 3, padding=1),
            nn.Conv2d(256, n_classes*6, 3, padding=1),
            nn.Conv2d(256, n_classes*4, 3, padding=1),
            nn.Conv2d(256, n_classes*4, 3, padding=1),
        ])
        self.locs = nn.ModuleList([
            nn.Conv2d(512, 4*4, 3, padding=1),
            nn.Conv2d(1024, 4*6, 3, padding=1),
            nn.Conv2d(512, 4*6, 3, padding=1),
            nn.Conv2d(256, 4*6, 3, padding=1),
            nn.Conv2d(256, 4*4, 3, padding=1),
            nn.Conv2d(256, 4*4, 3, padding=1),
        ])

    def forward(self, x: Tensor):
        """
        Parameters
        ----------
        x: Tensor of shape `(N, 3, H, W)`
            å›¾åƒæ•°æ®

        Returns
        -------
        loc: Tensor of shape `(N, n_priors, 4)`
            åç§»é‡

        conf: Tensor of shape `(N, n_priors, n_classes)`
            æ¯ä¸ªå…ˆéªŒæ¡†ä¸­çš„ç±»åˆ«ç½®ä¿¡åº¦

        prior: Tensor of shape `(n_priors, 4)`
            å…ˆéªŒæ¡†
        """
        loc = []
        conf = []

        # å­˜å‚¨ conv4_3(l2æ ‡å‡†åŒ–å)ã€conv7ã€conv8_2ã€conv9_2ã€conv10_2ã€conv11_2 çš„ç‰¹å¾å›¾
        sources = []

        # æ‰¹å¤§å°
        N = x.size(0)

        # è®¡ç®—ä» conv4_3 è¾“å‡ºçš„ç‰¹å¾å›¾
        for layer in self.vgg[:23]:
            x = layer(x)

        # ä¿å­˜ conv4_3 è¾“å‡ºçš„ l2 æ ‡å‡†åŒ–ç»“æœ
        sources.append(self.l2norm(x))

        # è®¡ç®— vgg16 åé¢å‡ ä¸ªå·ç§¯å±‚çš„ç‰¹å¾å›¾
        for layer in self.vgg[23:]:
            x = layer(x)

        # ä¿å­˜ conv7 çš„è¾“å‡ºçš„ç‰¹å¾å›¾
        sources.append(x)

        # è®¡ç®—åé¢å‡ ä¸ªå·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾
        for i, layer in enumerate(self.extras):
            x = F.relu(layer(x), inplace=True)
            if i % 2 == 1:
                sources.append(x)

        # ä½¿ç”¨åˆ†ç±»å™¨å’Œæ¢æµ‹å™¨è¿›è¡Œé¢„æµ‹å¹¶å°†é€šé“å˜ä¸ºæœ€åä¸€ä¸ªç»´åº¦æ–¹ä¾¿å †å 
        for x, conf_layer, loc_layer in zip(sources, self.confs, self.locs):
            # å‰é¢å­˜å‚¨çš„6ä¸ªç‰¹å¾å›¾åˆ†åˆ«åœ¨æ¯åƒç´ ç‚¹ç”Ÿæˆ 4ã€6ã€6ã€6ã€4ã€4 ä¸ªé”šæ¡†åŠå…¶åç§»é‡ã€ç±»åˆ«å€¼
            loc.append(loc_layer(x).permute(0, 2, 3, 1).contiguous())
            conf.append(conf_layer(x).permute(0, 2, 3, 1).contiguous())

        # è¾“å‡ºç»´åº¦ä¸º (batch_size, n_priors, n_classes) å’Œ (batch_size, n_priors, 4)
        conf = torch.cat([i.view(N, -1) for i in conf], dim=1)
        loc = torch.cat([i.view(N, -1) for i in loc], dim=1)

        return loc.view(N, -1, 4), conf.view(N, -1, self.n_classes),  self.prior

    @torch.no_grad()
    def predict(self, x: Tensor):
        """
        Parameters
        ----------
        x: Tensor of shape `(N, 3, H, W)`
            å›¾åƒæ•°æ®

        Returns
        -------
        out: Tensor of shape `(N, n_classes, top_k, 5)`
            æ£€æµ‹ç»“æœï¼Œæœ€åä¸€ä¸ªç»´åº¦çš„å‰å››ä¸ªå…ƒç´ ä¸ºè¾¹ç•Œæ¡†çš„åæ ‡ `(xmin, ymin, xmax, ymax)`ï¼Œæœ€åä¸€ä¸ªå…ƒç´ ä¸ºç½®ä¿¡åº¦
        """
        loc, conf, prior = self(x)
        return self.detector(loc, F.softmax(conf, dim=-1), prior.to(loc.device))

    def load(self, model_path: str, device: str):
        """ è½½å…¥æƒé‡

        Parameters
        ----------
        model_path: str or Path
            æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        """
        self.load_state_dict(torch.load(model_path, map_location=device))
        print('ğŸ§ª æˆåŠŸè½½å…¥ SSD æ¨¡å‹')
