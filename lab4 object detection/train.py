# coding:utf-8
import os
import math
import torch
import numpy as np
from tqdm import tqdm
from torch.nn import init
from torch import nn, optim, cuda
from torch.backends import cudnn

from ssd import SSD
from loss import SSDLoss
from utils.visdom import Visualizer
from utils.random_seed import setup_seed
from utils.lr_schedule_utils import WarmUpMultiStepLR
from utils.datetime_utils import datetime, time_delta

setup_seed(729)


class TrainPipeline:
    """ è®­ç»ƒ SSD æ¨¡åž‹ """

    def __init__(self, dataloader=None, vgg_path: str = None, ssd_path: str = None,
                 lr=5e-4, momentum=0.9, weight_decay=5e-4, batch_size=16, max_epoch=50,
                 use_gpu=True, lr_steps=(200, 300, 400), warm_up_factor=1/3,
                 warm_up_iters=50, **config):
        """
        Parameters
        ----------
        train_loader:
            è®­ç»ƒé›† DataLoader

        vgg_path: str
            é¢„è®­ç»ƒçš„ VGG16 æ¨¡åž‹æ–‡ä»¶è·¯å¾„

        ssd_path: Union[str, None]
            SSD æ¨¡åž‹æ–‡ä»¶è·¯å¾„ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§é€‰æ‹©:
            * å¦‚æžœä¸ä¸º `None`ï¼Œå°†ä½¿ç”¨æ¨¡åž‹æ–‡ä»¶ä¸­çš„å‚æ•°åˆå§‹åŒ– `SSD`
            * å¦‚æžœä¸º `None`ï¼Œå°†ä½¿ç”¨ `init.xavier` æ–¹æ³•åˆå§‹åŒ– VGG16 ä¹‹åŽçš„å·ç§¯å±‚å‚æ•°

        lr: float
            å­¦ä¹ çŽ‡

        momentum: float
            åŠ¨é‡

        weight_decay: float
            æƒé‡è¡°å‡

        batch_size: int
            è®­ç»ƒé›† batch å¤§å°

        max_epoch: int
            è®­ç»ƒè½®æ•°

        use_gpu: bool
            æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒ

        lr_steps: Tuple[int]
            å­¦ä¹ çŽ‡é€€ç«çš„èŠ‚ç‚¹

        warm_up_factor: float
            çƒ­å¯åŠ¨å› å­

        warm_up_iters: int
            è¿­ä»£å¤šå°‘æ¬¡æ‰ç»“æŸçƒ­å¯åŠ¨

        **config:
            å…ˆéªŒæ¡†ç”Ÿæˆã€å…ˆéªŒæ¡†å’Œè¾¹ç•Œæ¡†åŒ¹é…ä»¥åŠ NMS ç®—æ³•çš„é…ç½®
        """

        self.config.update(config)

        self.dataloader = dataloader
        self.max_epoch = max_epoch
        self.use_gpu = use_gpu
        self.batch_size = batch_size

        if use_gpu and cuda.is_available():
            self.device = torch.device('cuda')
            cudnn.benchmark = True
        else:
            self.device = torch.device('cpu')

        self.config = {
            # é€šç”¨é…ç½®
            'n_classes': 5+1,
            'variance': (0.1, 0.2),

            # å…ˆéªŒæ¡†ç”Ÿæˆé…ç½®
            "image_size": 300,
            'steps': [8, 16, 32, 64, 100, 300],
            'feature_maps': [38, 19, 10, 5, 3, 1],
            'min_sizes': [30, 60, 111, 162, 213, 264],
            'max_sizes': [60, 111, 162, 213, 264, 315],
            'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],

            # NMS é…ç½®
            'top_k': 1,
            'nms_thresh': 0.45,
            'conf_thresh': 0.01,

            # å…ˆéªŒæ¡†å’Œè¾¹ç•Œæ¡†åŒ¹é…é…ç½®
            'overlap_thresh': 0.5,

            # å›°éš¾æ ·æœ¬æŒ–æŽ˜é…ç½®
            'neg_pos_ratio': 3,

            #  è®¾å¤‡
            'device': self.device
        }

        # åˆ›å»ºæ¨¡åž‹
        self.model = SSD(**self.config).to(self.device)

        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.critorion = SSDLoss(**self.config)
        self.optimizer = optim.SGD(
            self.model.parameters(), lr, momentum=momentum, weight_decay=weight_decay)
        self.lr_schedule = WarmUpMultiStepLR(
            self.optimizer, lr_steps, 0.1, warm_up_factor, warm_up_iters)

        # åˆå§‹åŒ–æ¨¡åž‹
        if ssd_path:
            self.model.load_state_dict(torch.load(ssd_path))
            print('ðŸ§ª æˆåŠŸè½½å…¥ SSD æ¨¡åž‹ï¼š' + ssd_path)
        elif vgg_path:
            self.model.vgg.load_state_dict(torch.load(vgg_path))
            self.model.extras.apply(self.xavier)
            self.model.confs.apply(self.xavier)
            self.model.locs.apply(self.xavier)
            print('ðŸ§ª æˆåŠŸè½½å…¥ VGG16 æ¨¡åž‹ï¼š' + vgg_path)
        else:
            raise ValueError("å¿…é¡»æŒ‡å®šé¢„è®­ç»ƒçš„ VGG16 æ¨¡åž‹æ–‡ä»¶è·¯å¾„")

        self.vis = Visualizer('Train')

    def save(self, epoch):
        """ ä¿å­˜æ¨¡åž‹ """

        if not os.path.exists('./checkpoints/'):
            os.mkdir('./checkpoints/')

        self.model.eval()
        path = f'./model_{epoch}.pth'
        torch.save(self.model.state_dict(), path)

        print(f'\n\nðŸŽ‰ å·²å°†å½“å‰æ¨¡åž‹ä¿å­˜åˆ° {path}\n')

    @staticmethod
    def xavier(module):
        """ ä½¿ç”¨ xavier æ–¹æ³•åˆå§‹åŒ–æ¨¡åž‹çš„å‚æ•° """
        if not isinstance(module, nn.Conv2d):
            return

        init.xavier_uniform_(module.weight)
        init.constant_(module.bias, 0)

    def train(self):
        """ è®­ç»ƒæ¨¡åž‹ """

        print('ðŸš€ å¼€å§‹è®­ç»ƒï¼')

        bar_format = '{desc}{n_fmt:>2s}/{total_fmt:<3s}|{bar}|{postfix}'
        with tqdm(total=math.ceil(len(self.dataloader)), bar_format=bar_format) as bar:

            self.model.train()
            start_time = datetime.now()
            for epoch in range(self.max_epoch):
                loss_his = [[], [], []]
                for i, (images, targets) in enumerate(self.dataloader):
                    self.current_iter = i

                    bar.set_description(
                        f"\33[36mðŸŒŒ Epoch{epoch:2d}/{self.max_epoch} Batch")

                    # é¢„æµ‹è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦å’Œå…ˆéªŒæ¡†
                    pred = self.model(images.to(self.device))

                    # è®¡ç®—æŸå¤±å¹¶ã€åå‘ä¼ æ’­ã€å­¦ä¹ çŽ‡é€€ç«
                    self.optimizer.zero_grad()
                    loc_loss, conf_loss = self.critorion(pred, targets)
                    loss = loc_loss + conf_loss  # type:torch.Tensor
                    loss.backward()
                    self.optimizer.step()
                    # self.lr_schedule.step()

                    # ä¸°å¯Œè¿›åº¦æ¡å†…å®¹
                    cost_time = time_delta(start_time)
                    bar.set_postfix_str(
                        f'loss: {loss.item():.3f}, loc_loss: {loc_loss.item():.3f}, conf_loss: {conf_loss.item():.3f}, time: {cost_time}\33[0m')
                    bar.update()

                    # è®°å½•
                    loss_his[0].append(loss.item())
                    loss_his[1].append(loc_loss.item())
                    loss_his[2].append(conf_loss.item())

                # æ¯è½®æ›´æ–°è¿›åº¦æ¡
                start_time = datetime.now()
                print(
                    f'    Average loc_loss[{np.mean(loss_his[1]):.3f}]--conf_loss[{np.mean(loss_his[2]):.3f}]--loss[{np.mean(loss_his[0]):.3f}]')
                print('')
                bar.reset()
                self.save(epoch)

                # å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
                self.vis.plot(win='loss',
                              name='loc_loss', y=np.mean(loss_his[1]))
                self.vis.plot(win='loss',
                              name='conf_loss', y=np.mean(loss_his[2]))
                self.vis.plot(win='loss',
                              name='loss', y=np.mean(loss_his[0]))

        torch.cuda.empty_cache()


if __name__ == "__main__":
    # load dataset
    from dataset.data import load_data
    num_classes = 5
    batch_size = 8
    train_loader, _ = load_data(batch_size)

    # train config
    config = {
        'dataloader': train_loader,
        'n_classes': num_classes+1,
        'vgg_path': './vgg16_reducedfc.pth',
        'batch_size': batch_size,
    }

    # train
    train_pipeline = TrainPipeline(**config)
    train_pipeline.train()
